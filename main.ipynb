{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Importing essential libraries </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DataScience\\IDE\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import essential libraries\n",
    "import tensorflow  as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time as tm\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_loader\n",
    "\n",
    "import models\n",
    "import config_file as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset generator debugger\n",
    "\n",
    "debugging = False\n",
    "if debugging:\n",
    "    DBG = image_loader.DataBatchGenerator()\n",
    "\n",
    "    batch = DBG.get_train_data_batch()\n",
    "    print(batch['labels'].shape)\n",
    "    indices, lab_batch, gray_batch, labels = batch['index'], batch['lab_batch'], batch['gray_batch'].reshape([-1,256,256,1]), batch['labels']\n",
    "\n",
    "    plt.imshow(lab_batch[5])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(gray_batch[5].reshape([256, 256]), cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(lab_batch[5][:,:,0], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    print(lab_batch.shape)\n",
    "    print(gray_batch.shape)\n",
    "    print(indices.shape)\n",
    "    print(labels.shape)\n",
    "    \n",
    "    batch = DBG.get_test_data_batch()\n",
    "    print(batch['labels'].shape)\n",
    "    indices, lab_batch, gray_batch, labels = batch['index'], batch['lab_batch'], batch['gray_batch'].reshape([-1,256,256,1]), batch['labels']\n",
    "\n",
    "    plt.imshow(lab_batch[5])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(gray_batch[5].reshape([256, 256]), cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(lab_batch[5][:,:,0], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    print(lab_batch.shape)\n",
    "    print(gray_batch.shape)\n",
    "    print(indices.shape)\n",
    "    print(labels.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def display_parameters():\n",
    "    print(graphs)\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print(shape)\n",
    "        print(len(shape))\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            print(dim)\n",
    "            variable_parameters *= dim.value\n",
    "        print(variable_parameters)\n",
    "        total_parameters += variable_parameters\n",
    "    print(total_parameters*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training module </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training parameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "using_saved_model = False       # If checked enter model chkpt name in promt and corresponding model will be used\n",
    "\n",
    "# -- Parameters for labels optimizer\n",
    "alpha = 0.5\n",
    "labels_learning_rate = 0.001 * alpha # 0.5 is alpha in formula\n",
    "\n",
    "# -- Parameters for outputs optimizer\n",
    "outputs_learning_rate = 0.001\n",
    "\n",
    "# Dataset batch generator\n",
    "DBG = image_loader.DataBatchGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> This is the tf <i><b>graph model</b></i> for colorization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building out the model\n",
    "#######################################################################################\n",
    "# Pre-setting model\n",
    "colorization_network = models.ColorizationNetwork(config.NUM_LABELS)\n",
    "\n",
    "# Pre-setting inputs\n",
    "\n",
    "# -- For image coloring\n",
    "gray_inputs = tf.placeholder(dtype=tf.float32, shape=[None,256,256,1], name='gray_inputs')\n",
    "lab_inputs = tf.placeholder(dtype=tf.float32, shape=[None,256,256,3], name='lab_inputs')\n",
    "\n",
    "# -- For image labels\n",
    "label_inputs = tf.placeholder(dtype=tf.float32, shape=[None, config.NUM_LABELS], name='label_inputs')\n",
    "\n",
    "# Setting out losses and optimizers\n",
    "\n",
    "# -- For image outputs\n",
    "outputs_loss_fn = tf.losses.mean_squared_error\n",
    "outputs_optimizer = tf.train.AdamOptimizer(learning_rate=outputs_learning_rate)\n",
    "\n",
    "# -- For image labels\n",
    "labels_loss_fn = tf.losses.softmax_cross_entropy\n",
    "labels_optimizer = tf.train.AdamOptimizer(learning_rate=labels_learning_rate)   \n",
    "\n",
    "# Creating model:\n",
    "img_outputs, img_labels = colorization_network.forward(inputs=gray_inputs)\n",
    "\n",
    "# Buiilding graph for output image\n",
    "outputs_scaled = img_outputs*255.0 # Rescaling back to pixel values\n",
    "loss_outputs=outputs_loss_fn(lab_inputs[:,:,:,1:], outputs_scaled)\n",
    "train_outputs = outputs_optimizer.minimize(loss_outputs)\n",
    "\n",
    "# Building graph for output labels\n",
    "loss_labels = labels_loss_fn(label_inputs, img_labels)\n",
    "train_labels = labels_optimizer.minimize(loss_labels)\n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model saver and checkpoint names (with path)\n",
    "saver = tf.train.Saver()\n",
    "session_name = './models/model-checkpoint.ckpt'\n",
    "\n",
    "train_output_loss_vector_name = './models/outputs-loss-train.npy'\n",
    "train_label_loss_vector_name = './models/labels-loss-train.npy'\n",
    "test_output_loss_vector_name = './models/outputs-loss-train.npy'\n",
    "test_label_loss_vector_name = './models/labels-loss-train.npy'\n",
    "\n",
    "# Saving and loading sessions and losses \n",
    "if using_saved_model:\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    saver.restore(sess, session_name)\n",
    "    \n",
    "    test_output_losses = np.load(test_output_loss_vector_name).tolist()\n",
    "    test_label_losses = np.load(test_label_loss_vector_name).tolist()\n",
    "    train_output_losses = np.load(train_output_loss_vector_name).tolist()\n",
    "    train_label_losses = np.load(train_label_loss_vector_name).tolist()\n",
    "    \n",
    "# Creating sessions if required and losses\n",
    "else:\n",
    "    \n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    test_output_losses = []\n",
    "    test_label_losses = []\n",
    "    train_output_losses = []\n",
    "    train_label_losses = []\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training module and loop </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "############  Epoch : 2 ############\n",
      "\n",
      "Batch processed!!!\n",
      "Losses for train and test batch for this epoch :\n",
      "For train batch : \n",
      "...Computed loss for image : 3536.405517578125\n",
      "...Computed loss for labels : 0.0\n",
      "For test batch : \n",
      "...Computed loss for image : 4325.33154296875\n",
      "...Computed loss for labels : 0.0\n",
      "Time taken : 73.46517586708069\n",
      "####################################\n",
      "############  Epoch : 3 ############\n",
      "\n",
      "Batch processed!!!\n",
      "Losses for train and test batch for this epoch :\n",
      "For train batch : \n",
      "...Computed loss for image : 4412.984375\n",
      "...Computed loss for labels : 0.0\n",
      "For test batch : \n",
      "...Computed loss for image : 2446.229248046875\n",
      "...Computed loss for labels : 0.0\n",
      "Time taken : 70.32097458839417\n",
      "####################################\n",
      "############  Epoch : 4 ############\n",
      "\n",
      "Batch processed!!!\n",
      "Losses for train and test batch for this epoch :\n",
      "For train batch : \n",
      "...Computed loss for image : 2480.867919921875\n",
      "...Computed loss for labels : 0.0\n",
      "For test batch : \n",
      "...Computed loss for image : 292.698974609375\n",
      "...Computed loss for labels : 0.0\n",
      "Time taken : 74.33560085296631\n",
      "####################################\n",
      "############  Epoch : 5 ############\n",
      "\n",
      "Batch processed!!!\n",
      "Losses for train and test batch for this epoch :\n",
      "For train batch : \n",
      "...Computed loss for image : 265.1199035644531\n",
      "...Computed loss for labels : 0.0\n",
      "For test batch : \n",
      "...Computed loss for image : 1332.0667724609375\n",
      "...Computed loss for labels : 0.0\n",
      "Time taken : 71.84794998168945\n",
      "####################################\n",
      "############  Epoch : 6 ############\n",
      "\n",
      "Batch processed!!!\n",
      "Losses for train and test batch for this epoch :\n",
      "For train batch : \n",
      "...Computed loss for image : 1406.013916015625\n",
      "...Computed loss for labels : 0.0\n",
      "For test batch : \n",
      "...Computed loss for image : 1921.3525390625\n",
      "...Computed loss for labels : 0.0\n",
      "Time taken : 70.55751991271973\n",
      "####################################\n",
      "############  Epoch : 7 ############\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bc1aa79a13d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     computed_label_loss = sess.run(\n\u001b[0;32m     15\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mloss_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mgray_inputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mgray_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab_inputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlab_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_inputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Abhishek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Abhishek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Abhishek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Abhishek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Abhishek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Abhishek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training module function\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print(\"####################################\\n############  Epoch : {} ############\".format(epoch))\n",
    "    start_time = tm.time()\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    # ---------------    TRAINING MODULE    ---------------------------\n",
    "    # Getting the batch for training\n",
    "    batch = DBG.get_train_data_batch()\n",
    "    print()\n",
    "    lab_batch, gray_batch, labels = batch['lab_batch'], batch['gray_batch'].reshape([-1,256,256,1]), batch['labels']\n",
    "    gray_batch = gray_batch.reshape([config.BATCH_SIZE, 256, 256, 1])\n",
    "    \n",
    "    # Computing labels\n",
    "    computed_label_loss = sess.run(\n",
    "        (loss_labels, train_labels),\n",
    "        feed_dict={gray_inputs:gray_batch, lab_inputs:lab_batch, label_inputs:labels}\n",
    "    )\n",
    "    \n",
    "    # Computing outputs\n",
    "    computed_output_loss = sess.run(\n",
    "        (loss_outputs, train_outputs), \n",
    "        feed_dict={gray_inputs:gray_batch, lab_inputs:lab_batch, label_inputs:labels}\n",
    "    )\n",
    "    # ---------------------  STORING LOSSES-TRAINING  -----------------\n",
    "    train_output_losses.append(computed_output_loss[0])\n",
    "    train_label_losses.append(computed_label_loss[0])\n",
    "    # ----------------    TESTING MODULE    ---------------------------\n",
    "    # Getting the batch for testing\n",
    "    batch = DBG.get_test_data_batch()\n",
    "    lab_batch, gray_batch, labels = batch['lab_batch'], batch['gray_batch'].reshape([-1,256,256,1]), batch['labels']\n",
    "    gray_batch = gray_batch.reshape([config.BATCH_SIZE, 256, 256, 1])\n",
    "    \n",
    "    # Computing labels\n",
    "    computed_label_loss = sess.run(\n",
    "        loss_labels,\n",
    "        feed_dict={gray_inputs:gray_batch, lab_inputs:lab_batch, label_inputs:labels}\n",
    "    )\n",
    "    \n",
    "    # Computing outputs\n",
    "    computed_output_loss = sess.run(\n",
    "        loss_outputs,\n",
    "        feed_dict={gray_inputs:gray_batch, lab_inputs:lab_batch, label_inputs:labels}\n",
    "    )\n",
    "    \n",
    "    # ----------------------  STORING LOSSES-TESTING  -----------------\n",
    "    test_output_losses.append(computed_output_loss)\n",
    "    test_label_losses.append(computed_label_loss)\n",
    "    # --------------------------------------------------------------------------------------------------------------------\n",
    "    # ------- EVALUATE RESULTS TO PREVENT OVERFITTING ------------------\n",
    "    if epoch%10 == 0:\n",
    "        # Show losses for training\n",
    "        print(\"Display output loss graph - TRAIN:\")\n",
    "        plt.plot(train_output_losses)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Output loss')\n",
    "        plt.title(\"Output loss in epochs \")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Display label loss graph - TRAIN:\")\n",
    "        plt.plot(train_label_losses)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Output loss')\n",
    "        plt.title(\"Output loss in epochs \")\n",
    "        plt.show()\n",
    "        \n",
    "        # Show losses for testing\n",
    "        print(\"Display output loss graph - TEST:\")\n",
    "        plt.plot(test_output_losses)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Output loss')\n",
    "        plt.title(\"Output loss in epochs \")\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Display label loss graph - TEST:\")\n",
    "        plt.plot(test_label_losses)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Output loss')\n",
    "        plt.title(\"Output loss in epochs \")\n",
    "        plt.show()\n",
    "        \n",
    "    # --------------------------------------------------------------------------------------------------------------------\n",
    "    print('Batch processed!!!')\n",
    "    # ----- Save sessions and losses every few epochs --------------\n",
    "    if epoch%10 == 0:\n",
    "        print(\"Saving sessions and losses!!!\")\n",
    "        saver.save(sess, './models/temp.ckpt') # Save sessions\n",
    "        np.save('./models/train-temp-output-losses.npy', train_output_losses) # Save training losses for output\n",
    "        np.save('./models/train-temp-label-losses.npy', train_label_losses) # Save training losses for labels\n",
    "        np.save('./models/test-temp-output-losses.npy', test_output_losses) # Save training losses for output\n",
    "        np.save('./models/test-temp-label-losses.npy', test_label_losses) # Save training losses for labels\n",
    "        print(\"Session and losses saved!!!\")\n",
    "    # ------------- Display losses for train and test --------------\n",
    "    print('Losses for train and test batch for this epoch :')\n",
    "    print('For train batch : ')\n",
    "    print('...Computed loss for image : {}'.format(train_output_losses[-1]))\n",
    "    print('...Computed loss for labels : {}'.format(train_label_losses[-1]))\n",
    "    print('For test batch : ')\n",
    "    print('...Computed loss for image : {}'.format(test_output_losses[-1]))\n",
    "    print('...Computed loss for labels : {}'.format(test_label_losses[-1]))\n",
    "    # ---------------------------------------------\n",
    "    end_time = tm.time()\n",
    "    print('Time taken : {}'.format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluating results </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Evaluating losses </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show losses for training\n",
    "print(\"Display output loss graph - TRAIN:\")\n",
    "plt.plot(train_output_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Output loss')\n",
    "plt.title(\"Output loss in epochs \")\n",
    "plt.show()\n",
    "\n",
    "print(\"Display label loss graph - TRAIN:\")\n",
    "plt.plot(train_label_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Output loss')\n",
    "plt.title(\"Output loss in epochs \")\n",
    "plt.show()\n",
    "\n",
    "# Show losses for testing\n",
    "print(\"Display output loss graph - TEST:\")\n",
    "plt.plot(test_output_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Output loss')\n",
    "plt.title(\"Output loss in epochs \")\n",
    "plt.show()\n",
    "\n",
    "print(\"Display label loss graph - TEST:\")\n",
    "plt.plot(test_label_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Output loss')\n",
    "plt.title(\"Output loss in epochs \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Evaluating images </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model if user satisfied\n",
    "num_of_to_test_images = 10\n",
    "for i in range(num_of_to_test_images):\n",
    "    batch = DBG.get_test_image(index=None)\n",
    "    lab_batch, gray_batch, labels = batch['lab_batch'], batch['gray_batch'].reshape([-1,256,256,1]), batch['labels']\n",
    "\n",
    "    start_time = tm.time()\n",
    "    out_images = sess.run(\n",
    "        outputs_scaled,\n",
    "        feed_dict={\n",
    "            gray_inputs:gray_batch, \n",
    "            lab_inputs:lab_batch,\n",
    "            label_inputs:labels\n",
    "        }\n",
    "    )\n",
    "    out_images = np.concatenate([lab_batch[:,:,:,0].reshape([-1,256,256,1]), out_images], axis=3)\n",
    "    end_time = tm.time()\n",
    "\n",
    "    print(out_images.shape)\n",
    "    print(\"Image colored !!!\")\n",
    "    print(\"Time taken : {}\".format(end_time-start_time))\n",
    "\n",
    "    plt.imshow(gray_batch.reshape([256,256]), cmap='gray')\n",
    "    plt.title(\"Pokemon {} - Grayscale\".format(index))\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(lab_batch.reshape([256,256,3]))\n",
    "    plt.title(\"Pokemon {} - Ground truth\".format(index))\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(out_images.reshape([256,256,3]))\n",
    "    plt.title(\"Pokemon {} - Colored image\".format(index))\n",
    "    plt.show()\n",
    "    # print(lab_batch.reshape([256,256,3]))\n",
    "    # print(out_images.reshape([256,256,3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Were you satisfied with the results ? (Yes or No)\")\n",
    "answer = input()\n",
    "if answer is 'Yes':\n",
    "    saver.save(sess, session_name) # Save sessions\n",
    "    np.save(train_output_loss_vector_name, train_output_losses) # Save training losses for output\n",
    "    np.save(train_label_loss_vector_name, train_label_losses) # Save training losses for labels\n",
    "    np.save(test_output_loss_vector_name, test_output_losses) # Save training losses for output\n",
    "    np.save(test_label_loss_vector_name, test_label_losses) # Save training losses for labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Testing module </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
